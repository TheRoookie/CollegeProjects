# Car Parking Space Counter

An intelligent computer vision application that monitors a parking lot via a video feed and automatically detects, tracks, and classifies each parking space as **Empty** or **Occupied** in real-time.

---

## Table of Contents

- [Features](#features)
- [Syllabus Topic Coverage](#syllabus-topic-coverage)
- [Project Structure](#project-structure)
- [Technology Stack](#technology-stack)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage Guide](#usage-guide)
  - [Step 1 – Draw Parking ROIs](#step-1--draw-parking-rois)
  - [Step 2 – Launch the Application](#step-2--launch-the-application)
- [Configuration](#configuration)
- [Module Reference](#module-reference)
- [Architecture Overview](#architecture-overview)

---

## Features

- Real-time video processing from `.mp4` / `.avi` / `.mkv` files or RTSP streams
- Interactive ROI drawing tool to define parking-space polygons on any video
- YOLOv8 nano vehicle detection (auto-downloads weights on first run)
- Centroid-based object tracker with persistent vehicle IDs
- Adaptive-threshold pixel-count classifier — no GPU required
- Optional CNN classifier back-end for higher accuracy
- Dark-themed PyQt5 GUI with live video display and analytics sidebar
- Live counters: Total Spaces / Available / Occupied + occupancy progress bar
- Modular codebase — each CV concern is isolated in its own Python file
- YAML-driven configuration — no source changes needed to tune parameters

---

## Syllabus Topic Coverage

| # | Syllabus Topic | Implementation | File |
|---|---|---|---|
| 1 | **Video Processing** | `cv2.VideoCapture` frame-by-frame loop with FPS cap and automatic looping for file sources | `video_handler.py` |
| 2 | **Image Filtering** | Grayscale conversion → Gaussian Blur → Adaptive Thresholding applied to every segmented ROI patch | `classifier.py` |
| 3 | **Image Segmentation** | Per-spot polygon masks using `cv2.fillPoly` + `cv2.bitwise_and`; each spot is cropped independently | `roi_manager.py` |
| 4 | **Object Detection** | YOLOv8 nano (Ultralytics) filters COCO classes: car (2), motorcycle (3), bus (5), truck (7) | `detector.py` |
| 5 | **Object Tracking** | Centroid Tracker with optimal Hungarian-algorithm assignment (scipy) and configurable disappearance timeout | `tracker.py` |
| 6 | **Image Classification** | Binary classifier (`Empty = 0`, `Occupied = 1`) using thresholded pixel-count ratio; optional CNN back-end | `classifier.py` |

---

## Project Structure

```
parking_counter/
│
├── main.py             # Application entry point
├── config.yaml         # All tunable settings
├── requirements.txt    # pip dependencies
│
├── video_handler.py    # Video Processing module
├── roi_manager.py      # Image Segmentation + ROI persistence
├── detector.py         # Object Detection (YOLOv8 nano)
├── tracker.py          # Object Tracking (Centroid Tracker)
├── classifier.py       # Image Filtering + Image Classification
├── pipeline.py         # QThread: ties all CV modules together
├── ui.py               # PyQt5 GUI (main window + analytics sidebar)
├── draw_rois.py        # Interactive OpenCV ROI drawing tool
│
└── assets/
    ├── yolov8n.pt          # YOLO weights (auto-downloaded on first run)
    └── parking_spots.json  # ROI coordinates (generated by draw_rois.py)
```

---

## Technology Stack

| Component | Library / Tool |
|---|---|
| Language | Python 3.9+ |
| Computer Vision | OpenCV (`cv2`) |
| Object Detection | Ultralytics YOLOv8 nano |
| Deep Learning (optional CNN) | PyTorch + torchvision |
| Numerical Computing | NumPy, SciPy |
| User Interface | PyQt5 |
| Configuration | PyYAML |
| Image Utilities | Pillow |

---

## Installation

### 1. Clone / download the project

```bash
git clone <repo-url>
cd CV_Project/parking_counter
```

### 2. Create a virtual environment (recommended)

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS / Linux
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

> YOLOv8 nano weights (`yolov8n.pt`) are downloaded automatically by Ultralytics on first run. Place them manually in `assets/` to skip the download:
> ```
> assets/yolov8n.pt
> ```

---

## Quick Start

```bash
# 1. Draw parking ROIs on your video (one-time setup)
python draw_rois.py --video videos/Parking_Garage_Rooftop_Security_Surveillance_Camera_Footage_1080P.mp4

# 2. Launch the GUI
python main.py
```

Inside the app:
1. **Open Video** — select your `.mp4` or paste an RTSP URL
2. **Load ROIs** — load `assets/parking_spots.json`
3. **▶ Start** — begin real-time processing

---

## Usage Guide

### Step 1 – Draw Parking ROIs

Run the interactive ROI tool **once** to mark each parking space polygon:

```bash
python draw_rois.py --video path/to/parking_lot.mp4 --output assets/parking_spots.json
```

| Key / Action | Effect |
|---|---|
| Left-click | Add a vertex to the current polygon |
| Right-click | Close and save the current polygon (≥ 3 vertices required) |
| `u` | Undo the last vertex |
| `d` | Delete the most recently completed spot |
| `s` | **Save all spots** to the JSON file and exit |
| `q` / `Esc` | Quit without saving |

**Optional flags:**

```bash
python draw_rois.py --video video.mp4 --frame 150   # seek to frame 150 before snapshot
```

The saved JSON format:
```json
[
  { "id": 0, "polygon": [[x1,y1], [x2,y2], [x3,y3], [x4,y4]] },
  { "id": 1, "polygon": [[...]] }
]
```

### Step 2 – Launch the Application

```bash
python main.py
# or with a custom config:
python main.py --config path/to/config.yaml
```

**GUI Layout:**

```
┌──────────────────────────────────────────────────────────────┐
│  [Open Video]  [Load ROIs]  [Draw ROIs]  |  [▶ Start]        │
├──────────────────────────┬───────────────────────────────────┤
│                          │  Analytics                        │
│   Live Video Feed        │  Total Spaces:   12               │
│                          │  Available:       5               │
│   Green overlay = Empty  │  Occupied:        7               │
│   Red overlay = Occupied │                                   │
│                          │  Occupancy  [████████░░]  58%     │
│                          │                                   │
│                          │  Event Log                        │
│                          │  > [ROI] Loaded 12 spots          │
│                          │  > [Pipeline] Started.            │
└──────────────────────────┴───────────────────────────────────┘
│  Status bar                                                  │
└──────────────────────────────────────────────────────────────┘
```

---

## Configuration

All settings live in `config.yaml`. No source code changes are needed.

```yaml
video:
  source: ""              # leave blank to use the GUI file picker
  process_width: 640      # frames are resized to this width before inference
  max_fps: 30             # processing FPS cap (0 = no cap)

roi:
  coordinates_file: "assets/parking_spots.json"

detection:
  model_weights: "assets/yolov8n.pt"
  confidence_threshold: 0.45
  iou_threshold: 0.45
  vehicle_classes: [2, 3, 5, 7]   # COCO: car, motorcycle, bus, truck
  device: "cpu"                    # "cpu" | "cuda" | "mps"

tracker:
  max_distance: 50        # max pixel distance to match centroids
  max_disappeared: 20     # frames before a lost track is removed

classifier:
  method: "pixel_count"   # "pixel_count" | "cnn"
  pixel_threshold: 0.18   # fraction of foreground pixels → occupied
  blur_kernel: 5
  adaptive_block: 11
  adaptive_c: 2

display:
  empty_color:    [0, 200, 0]    # BGR green
  occupied_color: [0, 0, 220]    # BGR red
  box_thickness: 2
  font_scale: 0.5
```

---

## Module Reference

### `video_handler.py` — `VideoHandler`

Wraps `cv2.VideoCapture`. Yields `(original_frame, processed_frame)` tuples where `processed_frame` is resized to `process_width`. Automatically loops `.mp4` files when the stream ends.

```python
with VideoHandler("parking.mp4", process_width=640, max_fps=30) as vh:
    for raw, frame in vh.frames():
        ...
```

---

### `roi_manager.py` — `ROIManager` / `ParkingSpot`

Loads polygon coordinates from JSON, extracts per-spot masked patches using `cv2.fillPoly` + `cv2.bitwise_and`, and draws semi-transparent overlays.

```python
roi = ROIManager("assets/parking_spots.json")
roi.load()
patch = roi.extract_patch(frame, roi.spots[0])   # segmented crop
annotated = roi.draw_overlays(frame)
print(roi.empty_count, roi.occupied_count)
```

---

### `detector.py` — `VehicleDetector`

Wraps YOLOv8 nano. Model is loaded lazily on first call to `detect()`. Returns `List[Detection]` with `bbox`, `confidence`, `class_id`, and `label`.

```python
detector = VehicleDetector(model_path="assets/yolov8n.pt", confidence=0.45)
detections = detector.detect(frame)   # List[Detection]
```

---

### `tracker.py` — `CentroidTracker`

Implements centroid-based multi-object tracking. Uses `scipy.optimize.linear_sum_assignment` for optimal detection-to-track matching. Returns `Dict[int, Track]` mapping `track_id` → `Track`.

```python
tracker = CentroidTracker(max_distance=50, max_disappeared=20)
tracks = tracker.update([(x1,y1,x2,y2), ...])
for tid, track in tracks.items():
    print(tid, track.centroid)
```

---

### `classifier.py` — `SpaceClassifier`

Façade over two back-ends:

- **`pixel_count`** (default): Gaussian blur → Adaptive Threshold → non-zero pixel ratio
- **`cnn`**: Small two-conv PyTorch network loaded from a `.pt` checkpoint

```python
clf = SpaceClassifier(method="pixel_count", pixel_threshold=0.18)
status = clf.classify(patch)   # SpaceStatus.EMPTY or SpaceStatus.OCCUPIED
```

---

### `pipeline.py` — `PipelineThread`

`QThread` subclass that runs the full per-frame pipeline and emits Qt signals:

| Signal | Payload | Description |
|---|---|---|
| `frame_ready` | `np.ndarray` | Annotated BGR frame |
| `stats_updated` | `(int, int, int)` | total, empty, occupied counts |
| `error_occurred` | `str` | Non-fatal error message |
| `finished_signal` | — | Stream ended or `stop()` called |

---

### `draw_rois.py`

Standalone OpenCV script. Displays a single frame from the video as a background canvas. Mouse callbacks accumulate polygon vertices; `s` saves to JSON.

```bash
python draw_rois.py --video parking.mp4 --output assets/parking_spots.json --frame 60
```

---

## Architecture Overview

```
VideoHandler
    └─ yields frames
         │
         ├──► VehicleDetector (YOLOv8n)
         │         └─ List[Detection]
         │                  │
         │         CentroidTracker
         │                  └─ Dict[id, Track]
         │
         └──► ROIManager
                   ├─ extract_patch() per spot   ← Image Segmentation
                   │        │
                   │   SpaceClassifier           ← Image Filtering
                   │        │                   ← Image Classification
                   │   spot.status = empty/occupied
                   │
                   └─ draw_overlays() → annotated frame
                                              │
                                         PipelineThread
                                              │  (Qt signals)
                                              │
                                           MainWindow (PyQt5 GUI)
```
